{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49ffbd93",
   "metadata": {},
   "source": [
    "# Проект по анализу оттока клиентов банка\n",
    "## Описание задачи проекта\n",
    "Из «Бета-Банка» каждый месяц немного стали уходить клиенты. По данным банковских маркетологов сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "Необходимо спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Для проекта предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c197e93e",
   "metadata": {},
   "source": [
    "## Подготовка и получение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21e2acc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import random \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fbac887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#читаем файл с компа или с сайта\n",
    "try:\n",
    "    df = pd.read_csv('/home/dmitrii/Документы/ucheba/Churn.csv')\n",
    "except:\n",
    "    df = pd.read_csv('C:/Users/Dmitrii/Documents/Dstudy/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e9d2ea",
   "metadata": {},
   "source": [
    "Рассмотрим первые 5 строчек датафрейма и его параметры. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "902b793b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0     2.0       0.00              1          1               1   \n",
      "1     1.0   83807.86              1          0               1   \n",
      "2     8.0  159660.80              3          1               0   \n",
      "3     1.0       0.00              2          0               0   \n",
      "4     2.0  125510.82              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0   \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "print(df.head(),'\\n')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4265827a",
   "metadata": {},
   "source": [
    "## Исследование задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07addb2",
   "metadata": {},
   "source": [
    "10000 записей в датасете достаточно для обучения, но в столбце \"Tenure\" отсутствует около 1000 записей. Ввиду того, что эта информация непосредственно не должна влиять на результирующую переменную и маловероятно, что распределена нормально, то разумно заполнить пустые значения случайными значениями от 0 до 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01ad09e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#заполним пустые значения столбца Tenure\n",
    "df['Tenure'].fillna( random.randint(0,10), inplace=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6396e9",
   "metadata": {},
   "source": [
    "Т.к. алгоритм должен предсказывать поведение клиентов в будущем, а не в прошлом, то личная информация прошлых клиентов не несет никакой пользы для модели. Удалим столбцы RowNumber, CustomerId, Surname."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6572b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['RowNumber', 'CustomerId', 'Surname'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99b5fd0",
   "metadata": {},
   "source": [
    "Просматривая типы данных видно, что столбцы Geography и Gender необходимо закодировать. Пол легко можно закодировать по бинарному принципу одним столбцом, т.к. столбец содержит только значения Female и Male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d88025cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'] = pd.get_dummies(df['Gender'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfcb4f3",
   "metadata": {},
   "source": [
    "Страну закодируем присвоением порядкового номера категории с помощью OrdinalEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5a67c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CreditScore  Geography  Gender   Age  Tenure  Balance  NumOfProducts  \\\n",
      "0        228.0        0.0     0.0  24.0     2.0      0.0            0.0   \n",
      "1        217.0        2.0     0.0  23.0     1.0    743.0            0.0   \n",
      "2        111.0        0.0     0.0  24.0     8.0   5793.0            2.0   \n",
      "3        308.0        0.0     0.0  21.0     1.0      0.0            1.0   \n",
      "4        459.0        2.0     0.0  25.0     2.0   3696.0            0.0   \n",
      "\n",
      "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
      "0        1.0             1.0           5068.0     1.0  \n",
      "1        0.0             1.0           5639.0     0.0  \n",
      "2        1.0             0.0           5707.0     1.0  \n",
      "3        0.0             0.0           4704.0     0.0  \n",
      "4        1.0             1.0           3925.0     0.0  \n"
     ]
    }
   ],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "data_ordinal = pd.DataFrame(encoder.fit_transform(df),\n",
    "                            columns=df.columns)\n",
    "print(data_ordinal.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52445f9c",
   "metadata": {},
   "source": [
    "По таблице видно, что ряд столбцов имеют очент высокие абсолютные значения, что негативно сказывается для алгоритмов обучения. Однако перед стандартизацией значений необходимо разделить датасет на две части для исключения влияния функции стандартизации на тестовые данные, т.к. при стандартизации происходит деление на дисперсию и вычитание среднего всего датасета, а не только тестовой части. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc3272f",
   "metadata": {},
   "source": [
    "## Разделение датасейта\n",
    "Разделим датасет на три части - целевую и признаков. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16d7985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разделение на целевую и выборку с признаками\n",
    "target = data_ordinal['Exited']\n",
    "features = data_ordinal.drop('Exited', axis=1)\n",
    "#Разделение на обучающие и выборки для оценки\n",
    "features_train, features_var, target_train,target_var = train_test_split(\n",
    "    features, \n",
    "    target, \n",
    "    test_size=0.4, \n",
    "    random_state=12345)\n",
    "#Разделение на валидационную и тествую выборки\n",
    "features_valid, features_test, target_valid,target_test = train_test_split(\n",
    "    features_var, \n",
    "    target_var, \n",
    "    test_size=0.5, \n",
    "    random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d77326f",
   "metadata": {},
   "source": [
    "## Стандартизация значений\n",
    "Стандартизацию значений произведем при помощи метода StandardScaler(). Обработке подвергаются столбцы 'CreditScore', 'Age', 'Balance', 'Age','Tenure' и 'EstimatedSalary'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6954721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CreditScore  Geography  Gender       Age    Tenure   Balance  \\\n",
      "7479    -0.888356        2.0     1.0 -0.373277  0.810280  1.663957   \n",
      "3411     0.608996        0.0     0.0 -0.183370  0.810280  0.309701   \n",
      "6027     2.054357        1.0     1.0  0.481302 -0.802217  1.332696   \n",
      "1247    -1.460262        0.0     1.0 -1.417761  0.165281 -0.956910   \n",
      "3716     0.130675        1.0     0.0 -1.132902 -1.124717  1.529191   \n",
      "\n",
      "      NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \n",
      "7479            0.0        1.0             0.0        -0.190775  \n",
      "3411            0.0        0.0             0.0        -0.335352  \n",
      "6027            1.0        0.0             1.0         1.501017  \n",
      "1247            1.0        1.0             0.0        -1.075144  \n",
      "3716            0.0        0.0             0.0         1.515855  \n"
     ]
    }
   ],
   "source": [
    "#Столбцы для стандартизации\n",
    "numeric = ['CreditScore', 'Age', 'Balance', 'Age','Tenure', 'EstimatedSalary']\n",
    "#Инициализируем стандартизатор\n",
    "scaler = StandardScaler()\n",
    "#Обучаем стандартизатор на тренировочных данных\n",
    "scaler.fit(features_train[numeric])\n",
    "#Стандартизируем тренировочную и валидационную выборки\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])\n",
    "print(features_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31bd9a5",
   "metadata": {},
   "source": [
    "## Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb96898b",
   "metadata": {},
   "source": [
    "### Обучение несбалансированной выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd06a61",
   "metadata": {},
   "source": [
    "Посмотрим на балансировку класcов целевого параметра. Имеется явный перекос почти в 4 раза в пользу оставшихся клиентов, что является благом для банка, но не для модели обучения. Однако попытаемся обучить такую модель.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f410bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exited\n",
      "0    7963\n",
      "1    2037\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby('Exited')['Exited'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c9b7e4",
   "metadata": {},
   "source": [
    "### Обучение модели случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8028eaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во деревьев: 300   глубина: 6   F1: 0.5342   ROC_AUC: 0.8489\n",
      "Кол-во деревьев: 600   глубина: 6   F1: 0.5375   ROC_AUC: 0.8494\n",
      "Кол-во деревьев: 900   глубина: 6   F1: 0.5325   ROC_AUC: 0.8494\n",
      "Кол-во деревьев: 1200   глубина: 6   F1: 0.5357   ROC_AUC: 0.8491\n",
      "Кол-во деревьев: 300   глубина: 9   F1: 0.5638   ROC_AUC: 0.8507\n",
      "Кол-во деревьев: 600   глубина: 9   F1: 0.5651   ROC_AUC: 0.8511\n",
      "Кол-во деревьев: 900   глубина: 9   F1: 0.5647   ROC_AUC: 0.8516\n",
      "Кол-во деревьев: 1200   глубина: 9   F1: 0.5638   ROC_AUC: 0.8515\n",
      "Кол-во деревьев: 300   глубина: 12   F1: 0.5652   ROC_AUC: 0.8488\n",
      "Кол-во деревьев: 600   глубина: 12   F1: 0.5639   ROC_AUC: 0.8478\n",
      "Кол-во деревьев: 900   глубина: 12   F1: 0.563   ROC_AUC: 0.8482\n",
      "Кол-во деревьев: 1200   глубина: 12   F1: 0.5616   ROC_AUC: 0.8474\n",
      "-лучший результат-\n",
      "Кол-во деревьев: 600   глубина: 9   F1: 0.5651   ROC_AUC: 0.8511\n"
     ]
    }
   ],
   "source": [
    "# лучшие метрики\n",
    "f1_best = 0\n",
    "roc_auc_best=0\n",
    "# лучшие параметры случайного леса\n",
    "n_est_best = 0\n",
    "n_depth_best = 0\n",
    "\n",
    "for depth in range(6, 15, 3): \n",
    "    for est in range(300, 1300, 300):\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth = depth)\n",
    "        model.fit(features_train, target_train)\n",
    "        predicted_valid = model.predict(features_valid)\n",
    "        f1 = round( f1_score(target_valid, predicted_valid),4)\n",
    "        #roc_auc вычисление\n",
    "        probabilities_valid = model.predict_proba(features_valid)\n",
    "        probabilities_one_valid = probabilities_valid[:, 1]\n",
    "        roc_auc = round( roc_auc_score(target_valid, probabilities_one_valid),4)\n",
    "        print(\"Кол-во деревьев:\",est ,\"  глубина:\", depth,\"  F1:\", f1, \"  ROC_AUC:\", roc_auc)\n",
    "        \n",
    "        #ищем лучшую модель по количеству деревьев\n",
    "        if f1>f1_best and roc_auc>roc_auc_best:\n",
    "            f1_best = f1\n",
    "            roc_auc_best = roc_auc\n",
    "            n_est_best = est\n",
    "            n_depth_best = depth\n",
    "            model_fr_best = model\n",
    "\n",
    "probabilities_valid = model_fr_best.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "roc_auc = round( roc_auc_score(target_valid, probabilities_one_valid),4)\n",
    "\n",
    "print('-лучший результат-')\n",
    "print(\"Кол-во деревьев:\",n_est_best,\"  глубина:\", n_depth_best,\"  F1:\", f1_best , \"  ROC_AUC:\", roc_auc_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a483e540",
   "metadata": {},
   "source": [
    "Результат получился ниже требуемого заданием. Вероятнее всего сыграла негативную роль разбалансировка классов. Лучшие результаты в ряду деревьев 300, 600, 900, 1200 и глубине 6,9,12 показала модель с гиперпараметрами 900 деревьев и максимальной глубиной 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156597f7",
   "metadata": {},
   "source": [
    "### Обучение модели логистической регрессии\n",
    "Для сравнения обучим модель логистической регрессии "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87417f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во итераций: 500   F1: 0.2679   ROC_AUC: 0.7455\n",
      "Кол-во итераций: 20500   F1: 0.2679   ROC_AUC: 0.7455\n",
      "Кол-во итераций: 40500   F1: 0.2679   ROC_AUC: 0.7455\n",
      "Кол-во итераций: 60500   F1: 0.2679   ROC_AUC: 0.7455\n",
      "Кол-во итераций: 80500   F1: 0.2679   ROC_AUC: 0.7455\n",
      "Кол-во итераций: 100500   F1: 0.2679   ROC_AUC: 0.7455\n",
      "Кол-во итераций: 120500   F1: 0.2679   ROC_AUC: 0.7455\n",
      "Кол-во итераций: 140500   F1: 0.2679   ROC_AUC: 0.7455\n",
      "Кол-во итераций: 160500   F1: 0.2679   ROC_AUC: 0.7455\n",
      "Кол-во итераций: 180500   F1: 0.2679   ROC_AUC: 0.7455\n",
      "-лучший результат-\n",
      "Кол-во итераций: 500   F1: 0.2679   ROC_AUC: 0.7455\n"
     ]
    }
   ],
   "source": [
    "# лучшие метрики\n",
    "f1_best = 0\n",
    "roc_auc_best=0\n",
    "# лучшие параметры логистической регрессии\n",
    "n_iter_best = 0\n",
    "\n",
    "for n_iter in range(500, 200000, 20000): \n",
    "    model = LogisticRegression(random_state=12345, solver='lbfgs', max_iter=n_iter)\n",
    "    model.fit(features_train, target_train)\n",
    "    predicted_valid = model.predict(features_valid)\n",
    "    f1 = round( f1_score(target_valid, predicted_valid),4)\n",
    "    #вычисление roc_auc\n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    roc_auc = round( roc_auc_score(target_valid, probabilities_one_valid),4)\n",
    "    print(\"Кол-во итераций:\", n_iter,\"  F1:\", f1, \"  ROC_AUC:\", roc_auc)\n",
    "        \n",
    "    #ищем лучшую модель по количеству деревьев\n",
    "    if f1>f1_best and roc_auc>roc_auc_best:\n",
    "            f1_best = f1\n",
    "            roc_auc_best = roc_auc\n",
    "            n_iter_best = n_iter\n",
    "            model_log_best = model\n",
    "\n",
    "predicted_valid = model_log_best.predict(features_valid)\n",
    "f1 = round( f1_score(target_valid, predicted_valid), 4)\n",
    "#получаем вероятности признака 1\n",
    "probabilities_valid = model_log_best.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "roc_auc = round( roc_auc_score(target_valid, probabilities_one_valid),4)\n",
    "print('-лучший результат-')\n",
    "print(\"Кол-во итераций:\",n_iter_best,\"  F1:\", f1, \"  ROC_AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454729c2",
   "metadata": {},
   "source": [
    "Алгоритм не улучшает результатов при увеличении гиперпараметров. Вероятно этот алгоритм слабо подходит для решения задачи. Результаты ниже требуемых по ТЗ и ниже полученных моделью случайного леса."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5458abd4",
   "metadata": {},
   "source": [
    "Попробуем устранить разбалансировку классов, т.к. вероятно она снижает качество результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e281351",
   "metadata": {},
   "source": [
    "## Борьба с дисбалансом\n",
    "Посмотрим на балансировку класcов целевого параметра. Имеется явный перекос почти в 4 раза в пользу оставшихся клиентов, что является благом для банка, но не для модели обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24c8c53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exited\n",
      "0    7963\n",
      "1    2037\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby('Exited')['Exited'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c420cd",
   "metadata": {},
   "source": [
    "Устраним балансировку с помощью увеличения количества признаков с исходом \"1\". Для этого воспользуемся функцией upsample. В результате получаем перемешанный и увеличенный в 3 раза признак с исходом \"1\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26c6864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68af6cc8",
   "metadata": {},
   "source": [
    "Так же попробуем устранить разбалансировку путем уменьшения количества признаков с исходом \"0\". Для этого воспользуемся функцией downsample. В результате получаем перемешанный и уменьшенный в 3 раза датасет с исходом \"0\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfbd9f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345)\n",
    "    \n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b9eaf2",
   "metadata": {},
   "source": [
    "Так же балансировку можно устранить путем изменения параметров решателя с помощью изменения веса. Этот прием технически одинаков с upsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f278f126",
   "metadata": {},
   "source": [
    "## Обучение отбалансированной модели\n",
    "### Обучение отбалансированной upsampling модели случайного леса\n",
    "Обучим модель случайного леса на отбаласированном \"вверх\" датасете и посмотрим на результаты валидационной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cf21e03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во деревьев: 300   глубина: 5   F1: 0.6228   ROC_AUC: 0.8461\n",
      "Кол-во деревьев: 500   глубина: 5   F1: 0.6212   ROC_AUC: 0.8474\n",
      "Кол-во деревьев: 700   глубина: 5   F1: 0.6228   ROC_AUC: 0.8474\n",
      "Кол-во деревьев: 900   глубина: 5   F1: 0.6221   ROC_AUC: 0.8474\n",
      "Кол-во деревьев: 300   глубина: 7   F1: 0.63   ROC_AUC: 0.8533\n",
      "Кол-во деревьев: 500   глубина: 7   F1: 0.6284   ROC_AUC: 0.8534\n",
      "Кол-во деревьев: 700   глубина: 7   F1: 0.6318   ROC_AUC: 0.8535\n",
      "Кол-во деревьев: 900   глубина: 7   F1: 0.6302   ROC_AUC: 0.8539\n",
      "Кол-во деревьев: 300   глубина: 9   F1: 0.6209   ROC_AUC: 0.8533\n",
      "Кол-во деревьев: 500   глубина: 9   F1: 0.6238   ROC_AUC: 0.8532\n",
      "Кол-во деревьев: 700   глубина: 9   F1: 0.6256   ROC_AUC: 0.8532\n",
      "Кол-во деревьев: 900   глубина: 9   F1: 0.6223   ROC_AUC: 0.8532\n",
      "Кол-во деревьев: 300   глубина: 11   F1: 0.6022   ROC_AUC: 0.8486\n",
      "Кол-во деревьев: 500   глубина: 11   F1: 0.6118   ROC_AUC: 0.8488\n",
      "Кол-во деревьев: 700   глубина: 11   F1: 0.6078   ROC_AUC: 0.8491\n",
      "Кол-во деревьев: 900   глубина: 11   F1: 0.6061   ROC_AUC: 0.849\n",
      "-лучший результат-\n",
      "Кол-во деревьев: 700   глубина: 7   F1: 0.6318   ROC_AUC: 0.8535\n"
     ]
    }
   ],
   "source": [
    "# лучшие метрики\n",
    "f1_best = 0\n",
    "roc_auc_best=0\n",
    "# лучшие параметры случайного леса\n",
    "n_est_best = 0\n",
    "n_depth_best = 0\n",
    "\n",
    "for depth in range(5, 12, 2): \n",
    "    for est in range(300, 1000, 200):\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth = depth )\n",
    "        model.fit(features_upsampled, target_upsampled)\n",
    "        predicted_valid = model.predict(features_valid)\n",
    "        f1 = round( f1_score(target_valid, predicted_valid),4)\n",
    "        #вычисление roc_auc\n",
    "        probabilities_valid = model.predict_proba(features_valid)\n",
    "        probabilities_one_valid = probabilities_valid[:, 1]\n",
    "        roc_auc = round( roc_auc_score(target_valid, probabilities_one_valid),4)\n",
    "        print(\"Кол-во деревьев:\",est ,\"  глубина:\", depth,\"  F1:\", f1, \"  ROC_AUC:\", roc_auc)\n",
    "        \n",
    "        #ищем лучшую модель по количеству деревьев\n",
    "        if f1>f1_best and roc_auc>roc_auc_best:\n",
    "            f1_best = f1\n",
    "            roc_auc_best = roc_auc\n",
    "            n_est_best = est\n",
    "            n_depth_best = depth\n",
    "            model_fr_up_best = model\n",
    "\n",
    "predicted_valid = model_fr_up_best.predict(features_valid)\n",
    "f1 = round( f1_score(target_valid, predicted_valid), 4)\n",
    "probabilities_valid = model_fr_up_best.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "roc_auc = round( roc_auc_score(target_valid, probabilities_one_valid),4)\n",
    "print('-лучший результат-')\n",
    "print(\"Кол-во деревьев:\",n_est_best,\"  глубина:\", n_depth_best,\"  F1:\", f1, \"  ROC_AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d80a7d",
   "metadata": {},
   "source": [
    "Результаты метрики F1 превышают минимально требуемые по заданию. Метрика AUC_ROC на уровне не очень высоком. F1=0.627 ROC_AUC=0.77"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b18deb",
   "metadata": {},
   "source": [
    "### Обучение отбалансированной downsampling модели случайного леса\n",
    "Обучим модель случайного леса на отбаласированном \"вниз\" датасете и посмотрим на результаты валидационной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dfd1110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во деревьев: 300   глубина: 5   F1: 0.6219   ROC_AUC: 0.845\n",
      "Кол-во деревьев: 500   глубина: 5   F1: 0.618   ROC_AUC: 0.8458\n",
      "Кол-во деревьев: 700   глубина: 5   F1: 0.6164   ROC_AUC: 0.8459\n",
      "Кол-во деревьев: 900   глубина: 5   F1: 0.6156   ROC_AUC: 0.846\n",
      "Кол-во деревьев: 300   глубина: 7   F1: 0.6246   ROC_AUC: 0.8502\n",
      "Кол-во деревьев: 500   глубина: 7   F1: 0.625   ROC_AUC: 0.8508\n",
      "Кол-во деревьев: 700   глубина: 7   F1: 0.629   ROC_AUC: 0.8507\n",
      "Кол-во деревьев: 900   глубина: 7   F1: 0.6298   ROC_AUC: 0.8507\n",
      "Кол-во деревьев: 300   глубина: 9   F1: 0.6211   ROC_AUC: 0.8495\n",
      "Кол-во деревьев: 500   глубина: 9   F1: 0.6255   ROC_AUC: 0.8501\n",
      "Кол-во деревьев: 700   глубина: 9   F1: 0.6235   ROC_AUC: 0.8503\n",
      "Кол-во деревьев: 900   глубина: 9   F1: 0.6242   ROC_AUC: 0.8504\n",
      "Кол-во деревьев: 300   глубина: 11   F1: 0.6192   ROC_AUC: 0.8477\n",
      "Кол-во деревьев: 500   глубина: 11   F1: 0.6146   ROC_AUC: 0.8479\n",
      "Кол-во деревьев: 700   глубина: 11   F1: 0.616   ROC_AUC: 0.8477\n",
      "Кол-во деревьев: 900   глубина: 11   F1: 0.6195   ROC_AUC: 0.8482\n",
      "-лучший результат-\n",
      "Кол-во деревьев: 500   глубина: 7   F1: 0.625   ROC_AUC: 0.8508\n"
     ]
    }
   ],
   "source": [
    "# лучшие метрики\n",
    "f1_best = 0\n",
    "roc_auc_best=0\n",
    "# лучшие параметры случайного леса\n",
    "n_est_best = 0\n",
    "n_depth_best = 0\n",
    "\n",
    "for depth in range(5, 12, 2): \n",
    "    for est in range(300, 1000, 200):\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth = depth )\n",
    "        model.fit(features_downsampled, target_downsampled)\n",
    "        predicted_valid = model.predict(features_valid)\n",
    "        f1 = round( f1_score(target_valid, predicted_valid),4)\n",
    "        #вычисление roc_auc\n",
    "        probabilities_valid = model.predict_proba(features_valid)\n",
    "        probabilities_one_valid = probabilities_valid[:, 1]\n",
    "        roc_auc = round( roc_auc_score(target_valid, probabilities_one_valid),4)\n",
    "        print(\"Кол-во деревьев:\",est ,\"  глубина:\", depth,\"  F1:\", f1, \"  ROC_AUC:\", roc_auc)\n",
    "        \n",
    "        #ищем лучшую модель по количеству деревьев\n",
    "        if f1>f1_best and roc_auc>roc_auc_best:\n",
    "            f1_best = f1\n",
    "            roc_auc_best = roc_auc\n",
    "            n_est_best = est\n",
    "            n_depth_best = depth\n",
    "            model_fr_dw_best = model\n",
    "\n",
    "predicted_valid = model_fr_dw_best.predict(features_valid)\n",
    "f1 = round( f1_score(target_valid, predicted_valid), 4)\n",
    "probabilities_valid = model_fr_dw_best.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "roc_auc = round( roc_auc_score(target_valid, probabilities_one_valid),4)\n",
    "print('-лучший результат-')\n",
    "print(\"Кол-во деревьев:\",n_est_best,\"  глубина:\", n_depth_best,\"  F1:\", f1, \"  ROC_AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045155d4",
   "metadata": {},
   "source": [
    "### Обучение неотбалансированной модели с параметрами решателя\n",
    "Изменение выборок не единственный метод устранить разбалансированность. С помощью гиперпараметров решателя можно придать больший вес значениям, которые редко появляются. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60396350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во деревьев: 300   глубина: 5   F1: 0.6103   ROC_AUC: 0.8494\n",
      "Кол-во деревьев: 500   глубина: 5   F1: 0.616   ROC_AUC: 0.8496\n",
      "Кол-во деревьев: 700   глубина: 5   F1: 0.6142   ROC_AUC: 0.8492\n",
      "Кол-во деревьев: 900   глубина: 5   F1: 0.6149   ROC_AUC: 0.8492\n",
      "Кол-во деревьев: 300   глубина: 7   F1: 0.6157   ROC_AUC: 0.8538\n",
      "Кол-во деревьев: 500   глубина: 7   F1: 0.6188   ROC_AUC: 0.8534\n",
      "Кол-во деревьев: 700   глубина: 7   F1: 0.6197   ROC_AUC: 0.8534\n",
      "Кол-во деревьев: 900   глубина: 7   F1: 0.6167   ROC_AUC: 0.8533\n",
      "Кол-во деревьев: 300   глубина: 9   F1: 0.6227   ROC_AUC: 0.8541\n",
      "Кол-во деревьев: 500   глубина: 9   F1: 0.628   ROC_AUC: 0.8541\n",
      "Кол-во деревьев: 700   глубина: 9   F1: 0.6224   ROC_AUC: 0.854\n",
      "Кол-во деревьев: 900   глубина: 9   F1: 0.6249   ROC_AUC: 0.854\n",
      "Кол-во деревьев: 300   глубина: 11   F1: 0.5992   ROC_AUC: 0.8486\n",
      "Кол-во деревьев: 500   глубина: 11   F1: 0.6018   ROC_AUC: 0.849\n",
      "Кол-во деревьев: 700   глубина: 11   F1: 0.6005   ROC_AUC: 0.8493\n",
      "Кол-во деревьев: 900   глубина: 11   F1: 0.5935   ROC_AUC: 0.8496\n",
      "-лучший результат-\n",
      "Кол-во деревьев: 300   глубина: 9   F1: 0.6227   ROC_AUC: 0.8541\n"
     ]
    }
   ],
   "source": [
    "# лучшие метрики\n",
    "f1_best = 0\n",
    "roc_auc_best=0\n",
    "# лучшие параметры случайного леса\n",
    "n_est_best = 0\n",
    "n_depth_best = 0\n",
    "\n",
    "for depth in range(5, 12, 2): \n",
    "    for est in range(300, 1000, 200):\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth = depth, class_weight='balanced')\n",
    "        model.fit(features_train, target_train)\n",
    "        predicted_valid = model.predict(features_valid)\n",
    "        f1 = round( f1_score(target_valid, predicted_valid),4)\n",
    "        #вычисление roc_auc\n",
    "        probabilities_valid = model.predict_proba(features_valid)\n",
    "        probabilities_one_valid = probabilities_valid[:, 1]\n",
    "        roc_auc = round( roc_auc_score(target_valid, probabilities_one_valid),4)\n",
    "        print(\"Кол-во деревьев:\",est ,\"  глубина:\", depth,\"  F1:\", f1, \"  ROC_AUC:\", roc_auc)\n",
    "        \n",
    "        #ищем лучшую модель по количеству деревьев\n",
    "        if f1>f1_best and roc_auc>roc_auc_best:\n",
    "            f1_best = f1\n",
    "            roc_auc_best = roc_auc\n",
    "            n_est_best = est\n",
    "            n_depth_best = depth\n",
    "            model_fr_wt_best = model\n",
    "\n",
    "predicted_valid = model_fr_wt_best.predict(features_valid)\n",
    "f1 = round( f1_score(target_valid, predicted_valid), 4)\n",
    "probabilities_valid = model_fr_wt_best.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "roc_auc = round( roc_auc_score(target_valid, probabilities_one_valid), 4)\n",
    "print('-лучший результат-')\n",
    "print(\"Кол-во деревьев:\",n_est_best,\"  глубина:\", n_depth_best,\"  F1:\", f1, \"  ROC_AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004c2f3f",
   "metadata": {},
   "source": [
    "### Поиск лучшей модели по уровню метрик\n",
    "Рассматривались разные модели, причем у моделей менялись гиперапараметры, что в большинстве случаев приводило к изменению показателей метрик. По результатам валидационной выборки получились следующие параметры:\n",
    "- модель случайного дерева с дисбалансом..............F1: 0.5701...ROC_AUC: 0.8515\n",
    "- модель логистической регрессии с дисбалансом....F1: 0.2716...ROC_AUC: 0.7456\n",
    "- модель случайного леса с upsampling......................F1: 0.6302...ROC_AUC: 0.8538\n",
    "- модель случайного леса с downsampling.................F1: 0.6251...ROC_AUC: 0.8503\n",
    "- модель случайного леса с параметром balanced....F1: 0.6234...ROC_AUC: 0.8541\n",
    "\n",
    "\n",
    "Среди всех полученных моделей наилучшими параметрами обладают модели случайного леса. Модель логистической регрессии показывает результаты ниже требуемых. Устранение дисбаланса позволило повысить метрики моделей с 0,57 до 0,62, что отвечает минимальным требованиям к модели. Среди сбалансированных моделей результаты отличиются незначительно, в пределах погрешности, однако самый лучший результат показал метод upsampling с результатами гиперпараметров: количество деревьев 900, глубина 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7616a385",
   "metadata": {},
   "source": [
    "## Результаты на тестовой выборке\n",
    "Для тестовой выборке используется тестовая выборка, которая ранее не использовалась. Для анализа будет использоваться модель случайного леса, полученная с upsampling методом устранения дисбаланса. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bdf4d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат на тестовой выборке:   F1: 0.6046   ROC_AUC: 0.8529\n"
     ]
    }
   ],
   "source": [
    "predicted_test = model_fr_up_best.predict(features_test)\n",
    "f1 = round( f1_score(target_test, predicted_test), 4)\n",
    "probabilities_test = model_fr_up_best.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "roc_auc = round( roc_auc_score(target_test, probabilities_one_test), 4)\n",
    "print(\"Результат на тестовой выборке:\",\"  F1:\", f1, \"  ROC_AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1cfb8d",
   "metadata": {},
   "source": [
    "Результаты на тестовой выборке оказались заметно хуже, чем на валидационной, но превышают минимально требуемые. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3fe37f",
   "metadata": {},
   "source": [
    "## Заключение \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45532266",
   "metadata": {},
   "source": [
    "В данной работе на основе полученной информации был сформирован датасет для анализа. Для обучения модели произведены следующие подготовительные работы: удалены ненужные столбцы датасета, категориальные переменные были кодифицированы, значения чисел были нормализованны. Датасет был разбит на 3 части - для обучения, валидации и тестовую. На основе первых двух выборок были проверены модели случайного леса и логистической регрессии. Гиперпараметры моделей принимали различные значения в поисках максимизации метрик f1 и roc_auc. Полученные значения изначально оказались ниже требуемых. С целью повышения качества модели произведена балансировка значений некоторых столбцов тремя методами: upsampling, downsampling и параметрами решателя. В итоге была выбрана лучшая модель, которая на тестовой выборке показала результат F1=0.6023, ROC_AUC=0.85, что превышает минимально требуемый уровень. Модель готова к использованию и показывает удовлетворительные результаты. "
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2337,
    "start_time": "2022-12-23T14:31:49.843Z"
   },
   {
    "duration": 236,
    "start_time": "2022-12-23T14:31:52.183Z"
   },
   {
    "duration": 22,
    "start_time": "2022-12-23T14:31:52.421Z"
   },
   {
    "duration": 5,
    "start_time": "2022-12-23T14:31:53.790Z"
   },
   {
    "duration": 6,
    "start_time": "2022-12-23T14:31:55.294Z"
   },
   {
    "duration": 7,
    "start_time": "2022-12-23T14:31:57.724Z"
   },
   {
    "duration": 40,
    "start_time": "2022-12-23T14:31:58.434Z"
   },
   {
    "duration": 9,
    "start_time": "2022-12-23T14:31:59.326Z"
   },
   {
    "duration": 31,
    "start_time": "2022-12-23T14:31:59.771Z"
   },
   {
    "duration": 7,
    "start_time": "2022-12-23T14:32:01.094Z"
   },
   {
    "duration": 90,
    "start_time": "2022-12-23T14:32:01.451Z"
   },
   {
    "duration": 5281,
    "start_time": "2022-12-23T14:32:01.799Z"
   },
   {
    "duration": 6,
    "start_time": "2022-12-23T14:32:17.425Z"
   },
   {
    "duration": 17,
    "start_time": "2022-12-23T14:32:18.339Z"
   },
   {
    "duration": 4840,
    "start_time": "2022-12-23T14:32:19.275Z"
   },
   {
    "duration": 675,
    "start_time": "2022-12-23T14:32:24.117Z"
   },
   {
    "duration": 52,
    "start_time": "2022-12-26T18:38:27.722Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
